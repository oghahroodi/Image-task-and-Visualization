{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "-woU4Sodh6ND",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "# Assignment #2\n",
        "\n",
        "\n",
        "Deep Learning / Fall 1398, Iran University of Science and Technology\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "JWitIy1viFuD",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "**Please pay attention to these notes:**\n",
        "\n",
        "<br/>\n",
        "- **Assignment Due: ** 1398/9/23 23:59\n",
        "- If you need any additional information, please review the assignment page on the course website.\n",
        "- We always recommend co-operation and discussion in groups for assignments. However, each student has to finish all the questions by himself/herself. If our matching system identifies any sort of copying, you'll be responsible for consequences. So, please mention his/her name if you have a team-mate.\n",
        "- Students who audit this course should submit their assignments like other students to be qualified for attending the rest of the sessions.\n",
        "- Finding any sort of copying will zero down that assignment grade and also will be counted as two negative assignment for your final score.\n",
        "- When you are ready to submit, please follow the instructions at the end of this notebook.\n",
        "- If you have any questions about this assignment, feel free to drop us a line. You may also post your questions on the course Forum page.\n",
        "- You must run this notebook on Google Colab platform, it depends on Google Colab VM for some of its dependencies.\n",
        "- **Before starting to work on the assignment Please fill your name in the next section *AND Remember to RUN the cell.* **\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "Assignment Page: []()\n",
        "\n",
        "Course Forum: [https://groups.google.com/forum/#!forum/dl981/](https://groups.google.com/forum/#!forum/dl981/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "0ejALNiDCWnd",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "Vjwf6dWNCIQP",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Fill your information here & run the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "id": "NeLkOPE6Qwr7",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3433af0b-1987-4dbe-a50b-2bde76a53774"
      },
      "source": [
        "#@title Enter your information & \"RUN the cell!!\" { run: \"auto\" }\n",
        "student_id = 95521378 #@param {type:\"integer\"}\n",
        "student_name = \"Omid Ghahroodi\" #@param {type:\"string\"}\n",
        "Your_Github_account_Email = \"oghahroodi98@gmail.com\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"your student id:\", student_id)\n",
        "print(\"your name:\", student_name)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "ASSIGNMENT_PATH = Path('asg02')\n",
        "ASSIGNMENT_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your student id: 95521378\n",
            "your name: Omid Ghahroodi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "QfSFVOaKvlDb",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "# 1. Special Bus Line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "UmprL4aETrj8",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Consider the public transport bus service. It has many gates on roads in the city and a particular lane for bus transportation.\n",
        "\n",
        "\n",
        "This lane is also used for the transportation of emergency vehicles like ambulances, police cars and fire trucks, and private cars are banned from using it.\n",
        "\n",
        "\n",
        "Your task is to create a system to classify these two classes of vehicles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "NLU26ncrYZL5",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### Dataset\n",
        "---\n",
        "In this task, you should build your dataset based on an arbitrary approach. Of course, we suggest having a look at [this](https://forums.fast.ai/t/tips-for-building-large-image-datasets/26688) link if you do not have any idea about making the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "tFqWPWvot29x",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Please explain your dataset making method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bensiUcvZJ5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6bdff1df-9353-4c10-bc07-37bdf8481fd4"
      },
      "source": [
        "!pip install requests\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw6CwC_uaiPy"
      },
      "source": [
        "from requests import exceptions\n",
        "import argparse\n",
        "import requests\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def make_data_of_img(image, num_of_data, output_path):\n",
        "  # set your Microsoft Cognitive Services API key along with (1) the\n",
        "  # maximum number of results for a given search and (2) the group size\n",
        "  # for results (maximum of 50 per request)\n",
        "  API_KEY = \"eddad25108a44ff19b376aa45490041a\"\n",
        "  MAX_RESULTS = num_of_data\n",
        "  GROUP_SIZE = 50\n",
        "  \n",
        "  # set the endpoint API URL\n",
        "  URL = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n",
        "\n",
        "\n",
        "\n",
        "  # when attempting to download images from the web both the Python\n",
        "  # programming language and the requests library have a number of\n",
        "  # exceptions that can be thrown so let's build a list of them now\n",
        "  # so we can filter on them\n",
        "  EXCEPTIONS = set([IOError, FileNotFoundError,exceptions.RequestException, exceptions.HTTPError,exceptions.ConnectionError, exceptions.Timeout])\n",
        "  # EXCEPTIONS = set()\n",
        "\n",
        "  # store the search term in a convenience variable then set the\n",
        "  # headers and search parameters\n",
        "  term = image\n",
        "  headers = {\"Ocp-Apim-Subscription-Key\" : API_KEY}\n",
        "  params = {\"q\": term, \"offset\": 0, \"count\": GROUP_SIZE}\n",
        "\n",
        "  # make the search\n",
        "  print(\"[INFO] searching Bing API for '{}'\".format(term))\n",
        "  search = requests.get(URL, headers=headers, params=params)\n",
        "  search.raise_for_status()\n",
        "\n",
        "  # grab the results from the search, including the total number of\n",
        "  # estimated results returned by the Bing API\n",
        "  results = search.json()\n",
        "  estNumResults = min(results[\"totalEstimatedMatches\"], MAX_RESULTS)\n",
        "  print(\"[INFO] {} total results for '{}'\".format(estNumResults,term))\n",
        "\n",
        "  # initialize the total number of images downloaded thus far\n",
        "  total = 0\n",
        "\n",
        "\n",
        "  # loop over the estimated number of results in `GROUP_SIZE` groups\n",
        "  for offset in range(0, estNumResults, GROUP_SIZE):\n",
        "      # update the search parameters using the current offset, then\n",
        "      # make the request to fetch the results\n",
        "      print(\"[INFO] making request for group {}-{} of {}...\".format(offset, offset + GROUP_SIZE, estNumResults))\n",
        "      params[\"offset\"] = offset\n",
        "      search = requests.get(URL, headers=headers, params=params)\n",
        "      search.raise_for_status()\n",
        "      results = search.json()\n",
        "      print(\"[INFO] saving images for group {}-{} of {}...\".format(offset, offset + GROUP_SIZE, estNumResults))\n",
        "\n",
        "      # print(results)\n",
        "      # loop over the results\n",
        "      for v in results[\"value\"]:\n",
        "          # try to download the image\n",
        "          try:\n",
        "              # make a request to download the image\n",
        "              print(\"[INFO] fetching: {}\".format(v[\"contentUrl\"]))\n",
        "              r = requests.get(v[\"contentUrl\"], timeout=30)\n",
        "\n",
        "              # build the path to the output image\n",
        "              ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
        "              p = os.path.sep.join([output_path, \"{}{}\".format(str(total).zfill(8), ext)])\n",
        "              print(p)\n",
        "\n",
        "              # write the image to disk\n",
        "              f = open(p, \"wb\")\n",
        "              f.write(r.content)\n",
        "              f.close()\n",
        "\n",
        "          # catch any errors that would not unable us to download the\n",
        "          # image\n",
        "          except Exception as e:\n",
        "              # check to see if our exception is in our list of\n",
        "              # exceptions to check for\n",
        "              if type(e) in EXCEPTIONS:\n",
        "                  print(\"[INFO] skipping: {}\".format(v[\"contentUrl\"]))\n",
        "                  continue\n",
        "\n",
        "          # try to load the image from disk\n",
        "          image = cv2.imread(p)\n",
        "\n",
        "          # if the image is `None` then we could not properly load the\n",
        "          # image from disk (so it should be ignored)\n",
        "          if image is None:\n",
        "              print(\"[INFO] deleting: {}\".format(p))\n",
        "              os.remove(p)\n",
        "              continue\n",
        "\n",
        "          # update the counter\n",
        "          total += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ELKqKHQbLiR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "27d4d69c-b703-4719-cdb3-b2ee908b28f7"
      },
      "source": [
        "!rm -rf dataset\n",
        "!mkdir dataset\n",
        "!mkdir dataset/normal_vehicles\n",
        "!mkdir dataset/emergency_vehicles\n",
        "!mkdir dataset/emergency_vehicles/ambulances\n",
        "!mkdir dataset/emergency_vehicles/bus\n",
        "!mkdir dataset/emergency_vehicles/fire_trucks\n",
        "!mkdir dataset/emergency_vehicles/police_cars\n",
        "make_data_of_img(image='car',num_of_data=4000,output_path='dataset/normal_vehicles')\n",
        "make_data_of_img(image='ambulances',num_of_data=1000,output_path='dataset/emergency_vehicles/ambulances')\n",
        "make_data_of_img(image='bus',num_of_data=1000,output_path='dataset/emergency_vehicles/bus')\n",
        "make_data_of_img(image='fire trucks',num_of_data=1000,output_path='dataset/emergency_vehicles/fire_trucks')\n",
        "make_data_of_img(image='police cars',num_of_data=1000,output_path='dataset/emergency_vehicles/police_cars')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] searching Bing API for 'car'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d5b1b9fa7334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir dataset/emergency_vehicles/fire_trucks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir dataset/emergency_vehicles/police_cars'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmake_data_of_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'car'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset/normal_vehicles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmake_data_of_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ambulances'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset/emergency_vehicles/ambulances'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmake_data_of_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bus'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset/emergency_vehicles/bus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-9cf29c2440ea>\u001b[0m in \u001b[0;36mmake_data_of_img\u001b[0;34m(image, num_of_data, output_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] searching Bing API for '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;31m# grab the results from the search, including the total number of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: PermissionDenied for url: https://api.cognitive.microsoft.com/bing/v7.0/images/search?q=car&offset=0&count=50"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZRFvx_9Iy2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbeecba9-e95e-4025-de3d-87796134572a"
      },
      "source": [
        "!cp -r dataset drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot create directory 'drive/My Drive': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI8zIl5yn439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "25e6939b-27a4-4a20-876b-6c9a094dc377"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAqrL-0PEsXB"
      },
      "source": [
        "!rm -rf data\n",
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!mkdir data/train/emergency_vehicles/\n",
        "!mkdir data/train/normal_vehicles/\n",
        "\n",
        "!mkdir data/validation\n",
        "!mkdir data/validation/emergency_vehicles/\n",
        "!mkdir data/validation/normal_vehicles/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTPh4hyDmk6k"
      },
      "source": [
        "from shutil import copy\n",
        "import os\n",
        "import random\n",
        "\n",
        "c=0\n",
        "for i in os.listdir('drive/My Drive/dataset/normal_vehicles'):\n",
        "    if (c==500):\n",
        "        break\n",
        "    f = os.path.join('drive/My Drive/dataset/normal_vehicles',i)\n",
        "    if (f.split('.')[-1]=='jpg'):\n",
        "        # print(f)\n",
        "        c+=1\n",
        "        if (random.randint(0,9)<=7):\n",
        "            copy(f, '/content/data/train/normal_vehicles/')\n",
        "        else:\n",
        "            copy(f, '/content/data/validation/normal_vehicles/')\n",
        "\n",
        "\n",
        "c=0\n",
        "for i in os.listdir('drive/My Drive/dataset/emergency_vehicles/ambulances'):\n",
        "    if (c==125):\n",
        "        break\n",
        "    f = os.path.join('drive/My Drive/dataset/emergency_vehicles/ambulances',i)\n",
        "    if (f.split('.')[-1]=='jpg'):\n",
        "        # print(f)\n",
        "        c+=1\n",
        "        if (random.randint(0,9)<=7):\n",
        "            copy(f, '/content/data/train/emergency_vehicles/')\n",
        "        else:\n",
        "            copy(f, '/content/data/validation/emergency_vehicles/')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "c=0\n",
        "for i in os.listdir('drive/My Drive/dataset/emergency_vehicles/bus'):\n",
        "    if (c==125):\n",
        "        break\n",
        "    f = os.path.join('drive/My Drive/dataset/emergency_vehicles/bus',i)\n",
        "    if (f.split('.')[-1]=='jpg'):\n",
        "        # print(f)\n",
        "        c+=1\n",
        "        if (random.randint(0,9)<=7):\n",
        "            copy(f, '/content/data/train/emergency_vehicles/')\n",
        "        else:\n",
        "            copy(f, '/content/data/validation/emergency_vehicles/')\n",
        "\n",
        "\n",
        "c=0\n",
        "for i in os.listdir('drive/My Drive/dataset/emergency_vehicles/fire_trucks'):\n",
        "    if (c==125):\n",
        "        break\n",
        "    f = os.path.join('drive/My Drive/dataset/emergency_vehicles/fire_trucks',i)\n",
        "    if (f.split('.')[-1]=='jpg'):\n",
        "        # print(f)\n",
        "        c+=1\n",
        "        if (random.randint(0,9)<=7):\n",
        "            copy(f, '/content/data/train/emergency_vehicles/')\n",
        "        else:\n",
        "            copy(f, '/content/data/validation/emergency_vehicles/')\n",
        "\n",
        "\n",
        "\n",
        "c=0\n",
        "for i in os.listdir('drive/My Drive/dataset/emergency_vehicles/police_cars'):\n",
        "    if (c==125):\n",
        "        break\n",
        "    f = os.path.join('drive/My Drive/dataset/emergency_vehicles/police_cars',i)\n",
        "    if (f.split('.')[-1]=='jpg'):\n",
        "        # print(f)\n",
        "        c+=1\n",
        "        if (random.randint(0,9)<=7):\n",
        "            copy(f, '/content/data/train/emergency_vehicles/')\n",
        "        else:\n",
        "            copy(f, '/content/data/validation/emergency_vehicles/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "Ob0fG9c9ws5w",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "In order to build our deep learning image dataset, we are going to utilize Microsoft’s Bing Image Search API, which is part of Microsoft’s Cognitive Services used to bring AI to vision, speech, text, and more to apps and software.  \n",
        "\n",
        "I did not want to have to open my browser or utilize browser extensions to download the image files from my search.\n",
        "\n",
        "First i registered into Microsoft’s Cognitive Services and got API keys and end points then i installed request library.\n",
        "The requests  package makes it super easy for us to make HTTP requests and not get bogged down in fighting with Python to gracefully handle requests.\n",
        "\n",
        "The one part of this script that you must modify is the API_KEY . You can grab an API key by logging into Microsoft Cognitive Services and selecting the service you’d like to use (as shown above where you need to click the “Get API Key” button). From there, simply paste the API key within the quotes for this variable.\n",
        "\n",
        "You can also modify MAX_RESULTS  and GROUP_SIZE  for your search. Here, I’m limiting my results to the first 4000  images for each class and returning the maximum number of images per request by the Bing API ( 50  total images).\n",
        "\n",
        "Then we’re going to loop over the current batch of image address and attempt to download each individual image to our output folder.\n",
        "\n",
        "We establish a try-catch block so that we can catch the possible EXCEPTIONS  which we defined earlier in the script. If we encounter an exception we’ll be skipping that particular image and moving forward\n",
        "\n",
        "We then try to open and write the file to disk.\n",
        "\n",
        "\n",
        "REF:https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otcIUS2gUwls"
      },
      "source": [
        "### Implementation\n",
        "---\n",
        "You can use from Keras in this assignment.\n",
        "\n",
        "Preprocess your data in this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwi-sxIHWC5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "bb7745f7-45eb-4d50-ae4f-f14f249d6015"
      },
      "source": [
        "from keras.layers import Activation, Input, Dropout,Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from random import shuffle \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib as plt\n",
        "\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "\n",
        "    Source\n",
        "    ------\n",
        "    https://github.com/fchollet/keras/issues/5400#issuecomment-314747992\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    \"\"\"Calculate the F1 score.\"\"\"\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * ((p * r) / (p + r))\n",
        "\n",
        "\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/validation'\n",
        "nb_train_samples = len(os.listdir('data/train/emergency_vehicles'))+len(os.listdir('data/train/normal_vehicles'))\n",
        "nb_validation_samples = len(os.listdir('data/validation/emergency_vehicles'))+len(os.listdir('data/validation/normal_vehicles'))\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "save_dir = os.path.join(os.getcwd(), 'asg02')\n",
        "model_name = 'HW2.{epoch:03d}.h5'\n",
        "\n",
        "filepath = os.path.join(save_dir, model_name)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELbn6xT1Yj99"
      },
      "source": [
        "Build and train your model in the following cell.\n",
        "\n",
        "Use generator and augmentation in order to feed data to the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jmcF4NnYj9-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a302d7b2-c277-47c7-c2f5-b23b6c041321"
      },
      "source": [
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), padding='same',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (5, 5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (5, 5), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (5, 5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=[\"accuracy\",f1,recall,precision])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 32)      2432      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 150, 150, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 146, 146, 32)      25632     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 146, 146, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 73, 73, 64)        51264     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 73, 73, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 69, 69, 64)        102464    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 69, 69, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 34, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 73984)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               37880320  \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 38,209,953\n",
            "Trainable params: 38,209,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGfZ4m8vYj-A"
      },
      "source": [
        "Now, test your model, report the f1-score, recall and precision, and then save the model in a file with path 'ASSIGNMENT_PATH / 'my_model.h5''.\n",
        "\n",
        "Plot loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tAPg7gHYj-B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "d6842307-8c2b-47fb-eec9-314fbb4ed1d3"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 470 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "29/29 [==============================] - 25s 860ms/step - loss: 5.0304 - acc: 0.6730 - f1: 0.7972 - recall: 0.9867 - precision: 0.6821 - val_loss: 8.8430 - val_acc: 0.4453 - val_f1: 0.6087 - val_recall: 1.0000 - val_precision: 0.4453\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 25s 861ms/step - loss: 5.3790 - acc: 0.6626 - f1: 0.7876 - recall: 1.0000 - precision: 0.6626 - val_loss: 8.7304 - val_acc: 0.4524 - val_f1: 0.6156 - val_recall: 1.0000 - val_precision: 0.4524\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 23s 800ms/step - loss: 5.2959 - acc: 0.6682 - f1: 0.7906 - recall: 0.9484 - precision: 0.6890 - val_loss: 7.9712 - val_acc: 0.5000 - val_f1: 0.6601 - val_recall: 1.0000 - val_precision: 0.5000\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 23s 808ms/step - loss: 5.5691 - acc: 0.6510 - f1: 0.7809 - recall: 0.9602 - precision: 0.6668 - val_loss: 9.3630 - val_acc: 0.4127 - val_f1: 0.5708 - val_recall: 1.0000 - val_precision: 0.4127\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 21s 724ms/step - loss: 5.4175 - acc: 0.6604 - f1: 0.7827 - recall: 0.9661 - precision: 0.6716 - val_loss: 9.1099 - val_acc: 0.4286 - val_f1: 0.5717 - val_recall: 1.0000 - val_precision: 0.4286\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 22s 749ms/step - loss: 5.1575 - acc: 0.6760 - f1: 0.7976 - recall: 0.9703 - precision: 0.6836 - val_loss: 8.9834 - val_acc: 0.4365 - val_f1: 0.5972 - val_recall: 1.0000 - val_precision: 0.4365\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 22s 755ms/step - loss: 5.1923 - acc: 0.6743 - f1: 0.7965 - recall: 0.9969 - precision: 0.6758 - val_loss: 8.0977 - val_acc: 0.4921 - val_f1: 0.6498 - val_recall: 1.0000 - val_precision: 0.4921\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 22s 753ms/step - loss: 5.0164 - acc: 0.6853 - f1: 0.8075 - recall: 1.0000 - precision: 0.6853 - val_loss: 8.6038 - val_acc: 0.4603 - val_f1: 0.6193 - val_recall: 1.0000 - val_precision: 0.4603\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 20s 699ms/step - loss: 5.1211 - acc: 0.6788 - f1: 0.8047 - recall: 1.0000 - precision: 0.6788 - val_loss: 9.1099 - val_acc: 0.4286 - val_f1: 0.5828 - val_recall: 1.0000 - val_precision: 0.4286\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 24s 840ms/step - loss: 5.0171 - acc: 0.6853 - f1: 0.8096 - recall: 0.9940 - precision: 0.6884 - val_loss: 8.3448 - val_acc: 0.4766 - val_f1: 0.6417 - val_recall: 1.0000 - val_precision: 0.4766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vsZla4CHlMF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "172ded59-ba09-40e3-b8e8-6d6a1ed50c8e"
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/validation'\n",
        "nb_train_samples = len(os.listdir('data/train/emergency_vehicles'))+len(os.listdir('data/train/normal_vehicles'))\n",
        "nb_validation_samples = len(os.listdir('data/validation/emergency_vehicles'))+len(os.listdir('data/validation/normal_vehicles'))\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "# build the VGG16 network\n",
        "m = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "print('Model loaded.')\n",
        "print(m.summary())\n",
        "# build a classifier model to put on top of the convolutional model\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten())\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(m)\n",
        "\n",
        "model.add(top_model)\n",
        "\n",
        "\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=[\"accuracy\",f1,recall,precision])\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded.\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 1)                 2097665   \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 16,812,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Found 470 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "29/29 [==============================] - 26s 889ms/step - loss: 0.7042 - acc: 0.6135 - f1: 0.7335 - recall: 0.8212 - precision: 0.6846 - val_loss: 0.7032 - val_acc: 0.5234 - val_f1: 0.6637 - val_recall: 1.0000 - val_precision: 0.5077\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.52344, saving model to /content/asg02/HW2.001.h5\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 24s 837ms/step - loss: 0.5963 - acc: 0.6976 - f1: 0.7847 - recall: 0.8549 - precision: 0.7404 - val_loss: 0.6789 - val_acc: 0.5794 - val_f1: 0.6371 - val_recall: 1.0000 - val_precision: 0.4829\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.52344 to 0.57937, saving model to /content/asg02/HW2.002.h5\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 24s 827ms/step - loss: 0.4640 - acc: 0.7981 - f1: 0.8580 - recall: 0.9429 - precision: 0.8001 - val_loss: 0.4347 - val_acc: 0.8333 - val_f1: 0.8484 - val_recall: 0.9718 - val_precision: 0.7562\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.57937 to 0.83333, saving model to /content/asg02/HW2.003.h5\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 24s 817ms/step - loss: 0.3981 - acc: 0.8326 - f1: 0.8775 - recall: 0.9156 - precision: 0.8584 - val_loss: 0.4331 - val_acc: 0.8175 - val_f1: 0.8264 - val_recall: 1.0000 - val_precision: 0.7177\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.83333\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 22s 752ms/step - loss: 0.3132 - acc: 0.8728 - f1: 0.9081 - recall: 0.9545 - precision: 0.8741 - val_loss: 0.3596 - val_acc: 0.8730 - val_f1: 0.8257 - val_recall: 0.7386 - val_precision: 0.9577\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.83333 to 0.87302, saving model to /content/asg02/HW2.005.h5\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 23s 783ms/step - loss: 0.3067 - acc: 0.8792 - f1: 0.9086 - recall: 0.9310 - precision: 0.8985 - val_loss: 0.4946 - val_acc: 0.7778 - val_f1: 0.8113 - val_recall: 1.0000 - val_precision: 0.6961\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87302\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 23s 779ms/step - loss: 0.3167 - acc: 0.8714 - f1: 0.9003 - recall: 0.9406 - precision: 0.8810 - val_loss: 0.2578 - val_acc: 0.8810 - val_f1: 0.8448 - val_recall: 0.8132 - val_precision: 0.8844\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.87302 to 0.88095, saving model to /content/asg02/HW2.007.h5\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 21s 735ms/step - loss: 0.2044 - acc: 0.9332 - f1: 0.9497 - recall: 0.9681 - precision: 0.9370 - val_loss: 0.3034 - val_acc: 0.8810 - val_f1: 0.8584 - val_recall: 0.9841 - val_precision: 0.7821\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.88095\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 21s 728ms/step - loss: 0.2031 - acc: 0.9210 - f1: 0.9340 - recall: 0.9565 - precision: 0.9190 - val_loss: 0.2518 - val_acc: 0.8968 - val_f1: 0.8591 - val_recall: 0.8535 - val_precision: 0.8889\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.88095 to 0.89683, saving model to /content/asg02/HW2.009.h5\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 24s 814ms/step - loss: 0.1756 - acc: 0.9353 - f1: 0.9495 - recall: 0.9485 - precision: 0.9566 - val_loss: 0.2976 - val_acc: 0.8906 - val_f1: 0.8831 - val_recall: 0.9750 - val_precision: 0.8144\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.89683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzZJtwpO7e0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "57ee8fdb-ba39-4d4b-d99c-f6f7d338bcf5"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB+zzinPBHOHKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "km9kgkDLYj-D"
      },
      "source": [
        "Please explain that what type of loss and accuracy you set for training your model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "OYHW1dV3Yj-D"
      },
      "source": [
        "I used binary crossentropy because it is a loss function that is used for single label categorization. This is when only one category is applicable for each data point. In other words, an example can belong to one class only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZet365LYj-E"
      },
      "source": [
        "Visualize some layers and analyze them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4g24ZdSYj-F"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image as pil_image\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras import layers\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
        "\n",
        "\n",
        "def deprocess_image(x):\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + K.epsilon())\n",
        "    x *= 0.25\n",
        "\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    x *= 255\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "\n",
        "def process_image(x, former):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.transpose((2, 0, 1))\n",
        "    return (x / 255 - 0.5) * 4 * former.std() + former.mean()\n",
        "\n",
        "\n",
        "def visualize_layer(model,\n",
        "                    layer_name,\n",
        "                    step=1.,\n",
        "                    epochs=15,\n",
        "                    upscaling_steps=9,\n",
        "                    upscaling_factor=1.2,\n",
        "                    output_dim=(412, 412),\n",
        "                    filter_range=(0, None)):\n",
        " \n",
        "\n",
        "    def _generate_filter_image(input_img,\n",
        "                               layer_output,\n",
        "                               filter_index):\n",
        "\n",
        "        s_time = time.time()\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            loss = K.mean(layer_output[:, filter_index, :, :])\n",
        "        else:\n",
        "            loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "        grads = K.gradients(loss, input_img)[0]\n",
        "        grads = normalize(grads)\n",
        "        iterate = K.function([input_img], [loss, grads])\n",
        "\n",
        "        intermediate_dim = tuple(\n",
        "            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            input_img_data = np.random.random(\n",
        "                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n",
        "        else:\n",
        "            input_img_data = np.random.random(\n",
        "                (1, intermediate_dim[0], intermediate_dim[1], 3))\n",
        "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
        "\n",
        "        for up in reversed(range(upscaling_steps)):\n",
        "            for _ in range(epochs):\n",
        "                loss_value, grads_value = iterate([input_img_data])\n",
        "                input_img_data += grads_value * step\n",
        "                if loss_value <= K.epsilon():\n",
        "                    return None\n",
        "\n",
        "            intermediate_dim = tuple(\n",
        "                int(x / (upscaling_factor ** up)) for x in output_dim)\n",
        "            img = deprocess_image(input_img_data[0])\n",
        "            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n",
        "                                                           pil_image.BICUBIC))\n",
        "            input_img_data = np.expand_dims(\n",
        "                process_image(img, input_img_data[0]), 0)\n",
        "\n",
        "        img = deprocess_image(input_img_data[0])\n",
        "        e_time = time.time()\n",
        "        print('Costs of filter {:3}: {:5.0f} ( {:4.2f}s )'.format(filter_index,\n",
        "                                                                  loss_value,\n",
        "                                                                  e_time - s_time))\n",
        "        return img, loss_value\n",
        "\n",
        "    def _draw_filters(filters, n=None):\n",
        "\n",
        "        if n is None:\n",
        "            n = int(np.floor(np.sqrt(len(filters))))\n",
        "        filters.sort(key=lambda x: x[1], reverse=True)\n",
        "        filters = filters[:n * n]\n",
        "\n",
        "        MARGIN = 5\n",
        "        width = n * output_dim[0] + (n - 1) * MARGIN\n",
        "        height = n * output_dim[1] + (n - 1) * MARGIN\n",
        "        stitched_filters = np.zeros((width, height, 3), dtype='uint8')\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                img, _ = filters[i * n + j]\n",
        "                width_margin = (output_dim[0] + MARGIN) * i\n",
        "                height_margin = (output_dim[1] + MARGIN) * j\n",
        "                stitched_filters[\n",
        "                    width_margin: width_margin + output_dim[0],\n",
        "                    height_margin: height_margin + output_dim[1], :] = img\n",
        "\n",
        "        save_img('vgg_{0:}_{1:}x{1:}.png'.format(layer_name, n), stitched_filters)\n",
        "\n",
        "    assert len(model.inputs) == 1\n",
        "    input_img = model.inputs[0]\n",
        "\n",
        "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
        "\n",
        "    output_layer = layer_dict[layer_name]\n",
        "    assert isinstance(output_layer, layers.Conv2D)\n",
        "\n",
        "    filter_lower = filter_range[0]\n",
        "    filter_upper = (filter_range[1]\n",
        "                    if filter_range[1] is not None\n",
        "                    else len(output_layer.get_weights()[1]))\n",
        "    assert(filter_lower >= 0\n",
        "           and filter_upper <= len(output_layer.get_weights()[1])\n",
        "           and filter_upper > filter_lower)\n",
        "    print('Compute filters {:} to {:}'.format(filter_lower, filter_upper))\n",
        "\n",
        "    processed_filters = []\n",
        "    for f in range(filter_lower, filter_upper):\n",
        "        img_loss = _generate_filter_image(input_img, output_layer.output, f)\n",
        "\n",
        "        if img_loss is not None:\n",
        "            processed_filters.append(img_loss)\n",
        "\n",
        "    print('{} filter processed.'.format(len(processed_filters)))\n",
        "    _draw_filters(processed_filters)\n",
        "\n",
        "LAYER_NAME = 'block4_conv1'\n",
        "print(m.summary())\n",
        "\n",
        "visualize_layer(m, LAYER_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "YRMn4ZREYj-H"
      },
      "source": [
        "شبکه دارای ساختار سلسله مراتبی است به طوری که فیلترهای نمایش داده شده در لایه‌های اول ویژگی های ساده ماننده خطوط عمودی را پیدا میکنند و در لایه های جلوتر این ویژگی ها باهم ترکیب شده و به عنوان مثال اژیر ماشین پلیس را پیدا میکنند."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "pBjq-MvamPXO",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "7o4q5LiFiOx1",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Congratulations! You finished the assignment & you're ready to submit your work. Please follow the instruction:\n",
        "\n",
        "1. Check and review your answers. Make sure all of the cell outputs are what you want. \n",
        "2. Select File > Save.\n",
        "3. Run **Create Submission** cell, It may take several minutes and it may ask you for your credential.\n",
        "4. Run **Download Submission** cell to obtain your submission as a zip file.\n",
        "5. Grab downloaded file (`dl_asg02__xx__xx.zip`) and submit it via [https://forms.gle/Fb7gvVJHp8RePvo6A](https://forms.gle/Fb7gvVJHp8RePvo6A)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "iWRUf35av3ZP",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "**Note: ** We need your Github token to create (if doesn't exist previously) new repository to store learned model data. Also Google Drive token enables us to download the current notebook & create a submission. If you are interested feel free to check our code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "cTytERc-vlaK",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "## Create Submission (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P_D5MYXiyeS"
      },
      "source": [
        "!rm -rf /content/iust-deep-learning-assignments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "id": "r4o37hc3AEUg",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "f489fb50-16de-4595-db82-1811a300f9ca"
      },
      "source": [
        "#@title\n",
        "! pip install -U --quiet PyDrive > /dev/null\n",
        "! wget -q https://github.com/github/hub/releases/download/v2.10.0/hub-linux-amd64-2.10.0.tgz \n",
        "  \n",
        "import os\n",
        "import time\n",
        "import yaml\n",
        "import json\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Javascript\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "asg_name = 'assignment_02'\n",
        "script_save = '''\n",
        "require([\"base/js/namespace\"],function(Jupyter) {\n",
        "    Jupyter.notebook.save_checkpoint();\n",
        "});\n",
        "'''\n",
        "repo_name = 'iust-deep-learning-assignments'\n",
        "submission_file_name = 'dl_asg02__%s__%s.zip'%(student_id, student_name.lower().replace(' ',  '_'))\n",
        "\n",
        "! tar xf hub-linux-amd64-2.10.0.tgz\n",
        "! cd hub-linux-amd64-2.10.0/ && chmod a+x install && ./install\n",
        "! hub config --global hub.protocol https\n",
        "! hub config --global user.email \"$Your_Github_account_Email\"\n",
        "! hub config --global user.name \"$student_name\"\n",
        "! hub api --flat -X GET /user\n",
        "! hub api -F affiliation=owner -X GET /user/repos > repos.json\n",
        "\n",
        "repos = json.load(open('repos.json'))\n",
        "repo_names = [r['name'] for r in repos]\n",
        "has_repository = repo_name in repo_names\n",
        "if not has_repository:\n",
        "  get_ipython().system_raw('! hub api -X POST -F name=%s /user/repos > repo_info.json' % repo_name)\n",
        "  repo_info = json.load(open('repo_info.json')) \n",
        "  repo_url = repo_info['clone_url']\n",
        "else:\n",
        "  for r in repos:\n",
        "    if r['name'] == repo_name:\n",
        "      repo_url = r['clone_url']\n",
        "  \n",
        "stream = open(\"/root/.config/hub\", \"r\")\n",
        "token = list(yaml.load_all(stream))[0]['github.com'][0]['oauth_token']\n",
        "repo_url_with_token = 'https://'+token+\"@\" +repo_url.split('https://')[1]\n",
        "\n",
        "! git clone \"$repo_url_with_token\"\n",
        "! cp -r \"$ASSIGNMENT_PATH\" \"$repo_name\"/\n",
        "! cd \"$repo_name\" && git add -A\n",
        "! cd \"$repo_name\" && git commit -m \"Add assignment 02 results\"\n",
        "! cd \"$repo_name\" && git push -u origin master\n",
        "\n",
        "sub_info = {\n",
        "    'student_id': student_id,\n",
        "    'student_name': student_name, \n",
        "    'repo_url': repo_url,\n",
        "    'asg_dir_contents': os.listdir(str(ASSIGNMENT_PATH)),\n",
        "    'dateime': str(time.time()),\n",
        "    'asg_name': asg_name\n",
        "}\n",
        "json.dump(sub_info, open('info.json', 'w'))\n",
        "\n",
        "Javascript(script_save)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('%s.ipynb'%asg_name) \n",
        "\n",
        "! jupyter nbconvert --to script \"$asg_name\".ipynb > /dev/null\n",
        "! jupyter nbconvert --to html \"$asg_name\".ipynb > /dev/null\n",
        "! zip \"$submission_file_name\" \"$asg_name\".ipynb \"$asg_name\".html \"$asg_name\".txt info.json > /dev/null\n",
        "\n",
        "print(\"##########################################\")\n",
        "print(\"Done! Submisson created, Please download using the bellow cell!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0;36m.login\u001b[m\toghahroodi\n",
            "\u001b[0;36m.id\u001b[m\t\u001b[0;35m44407313\u001b[m\n",
            "\u001b[0;36m.node_id\u001b[m\tMDQ6VXNlcjQ0NDA3MzEz\n",
            "\u001b[0;36m.avatar_url\u001b[m\thttps://avatars2.githubusercontent.com/u/44407313?v=4\n",
            "\u001b[0;36m.gravatar_id\u001b[m\t\n",
            "\u001b[0;36m.url\u001b[m\thttps://api.github.com/users/oghahroodi\n",
            "\u001b[0;36m.html_url\u001b[m\thttps://github.com/oghahroodi\n",
            "\u001b[0;36m.followers_url\u001b[m\thttps://api.github.com/users/oghahroodi/followers\n",
            "\u001b[0;36m.following_url\u001b[m\thttps://api.github.com/users/oghahroodi/following{/other_user}\n",
            "\u001b[0;36m.gists_url\u001b[m\thttps://api.github.com/users/oghahroodi/gists{/gist_id}\n",
            "\u001b[0;36m.starred_url\u001b[m\thttps://api.github.com/users/oghahroodi/starred{/owner}{/repo}\n",
            "\u001b[0;36m.subscriptions_url\u001b[m\thttps://api.github.com/users/oghahroodi/subscriptions\n",
            "\u001b[0;36m.organizations_url\u001b[m\thttps://api.github.com/users/oghahroodi/orgs\n",
            "\u001b[0;36m.repos_url\u001b[m\thttps://api.github.com/users/oghahroodi/repos\n",
            "\u001b[0;36m.events_url\u001b[m\thttps://api.github.com/users/oghahroodi/events{/privacy}\n",
            "\u001b[0;36m.received_events_url\u001b[m\thttps://api.github.com/users/oghahroodi/received_events\n",
            "\u001b[0;36m.type\u001b[m\tUser\n",
            "\u001b[0;36m.site_admin\u001b[m\t\u001b[1;33mfalse\u001b[m\n",
            "\u001b[0;36m.name\u001b[m\tOmid Ghahroodi\n",
            "\u001b[0;36m.company\u001b[m\t\n",
            "\u001b[0;36m.blog\u001b[m\t\n",
            "\u001b[0;36m.location\u001b[m\t\n",
            "\u001b[0;36m.email\u001b[m\t\n",
            "\u001b[0;36m.hireable\u001b[m\t\n",
            "\u001b[0;36m.bio\u001b[m\tCE student at Iran University of Science and Technology\r\\nResearch interests:AI, Quantum  Computing, Cryptography\n",
            "\u001b[0;36m.public_repos\u001b[m\t\u001b[0;35m16\u001b[m\n",
            "\u001b[0;36m.public_gists\u001b[m\t\u001b[0;35m0\u001b[m\n",
            "\u001b[0;36m.followers\u001b[m\t\u001b[0;35m16\u001b[m\n",
            "\u001b[0;36m.following\u001b[m\t\u001b[0;35m14\u001b[m\n",
            "\u001b[0;36m.created_at\u001b[m\t2018-10-23T15:07:01Z\n",
            "\u001b[0;36m.updated_at\u001b[m\t2019-12-19T23:36:13Z\n",
            "Cloning into 'iust-deep-learning-assignments'...\n",
            "warning: You appear to have cloned an empty repository.\n",
            "[master (root-commit) 823a7b4] Add assignment 02 results\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 asg02/HW2.009.h5\n",
            "Counting objects: 4, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (2/2), done.\n",
            "Writing objects: 100% (4/4), 119.72 MiB | 5.96 MiB/s, done.\n",
            "Total 4 (delta 0), reused 0 (delta 0)\n",
            "remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
            "remote: error: Trace: d1a59652ccce0a36f487b762f73c0b8d\u001b[K\n",
            "remote: error: See http://git.io/iEPt8g for more information.\u001b[K\n",
            "remote: error: File asg02/HW2.009.h5 is 128.33 MB; this exceeds GitHub's file size limit of 100.00 MB\u001b[K\n",
            "To https://github.com/oghahroodi/iust-deep-learning-assignments.git\n",
            " ! [remote rejected] master -> master (pre-receive hook declined)\n",
            "error: failed to push some refs to 'https://4dfa12054dbdb02a08c6d1f65d44ba70f6971b16@github.com/oghahroodi/iust-deep-learning-assignments.git'\n",
            "[NbConvertApp] Converting notebook assignment_02.ipynb to script\n",
            "[NbConvertApp] Writing 29447 bytes to assignment_02.py\n",
            "[NbConvertApp] Converting notebook assignment_02.ipynb to html\n",
            "[NbConvertApp] Writing 995663 bytes to assignment_02.html\n",
            "##########################################\n",
            "Done! Submisson created, Please download using the bellow cell!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "id": "mX9OFzaLtYu_",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "## Download Submission (Run the cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "id": "PUzTlnX1nS8X",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#@title\n",
        "files.download(submission_file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPSE_erOYj-O"
      },
      "source": [
        "If that cell makes an error when running you can download file dl_asg02_your_struden_id_your_name.zip from left panel and files section by right-clicking on it and choosing download button."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9KaPEsgPruT"
      },
      "source": [
        "# Special Thanks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOXZZrFjPxWO"
      },
      "source": [
        "Special thanks to Amirhossein Kazemnejad and Kiamehr Razaee for creating the template of deep learning course assignments."
      ]
    }
  ]
}